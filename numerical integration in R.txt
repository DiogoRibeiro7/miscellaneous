trapezoid <- function(fun, a, b, n=100) {
	# numerical integral of fun from a to b
	# using the trapezoid rule with n subdivisions
	# assume a < b and n is a positive integer
	h <- (b-a)/n
	x <- seq(a, b, by=h)
	y <- fun(x)
	s <- h * (y[1]/2 + sum(y[2:n]) + y[n+1]/2)
	return(s)
}


simpson <- function(fun, a, b, n=100) {
	# numerical integral using Simpson's rule
	# assume a < b and n is an even positive integer
	h <- (b-a)/n
	x <- seq(a, b, by=h)
	if (n == 2) {
		s <- fun(x[1]) + 4*fun(x[2]) +fun(x[3])
	} else {
		s <- fun(x[1]) + fun(x[n+1]) + 2*sum(fun(x[seq(2,n,by=2)])) + 4 *sum(fun(x[seq(3,n-1, by=2)]))
	}
	s <- s*h/3
	return(s)
}


simpson_v2 <- function(fun, a, b, n=100) {
	# numerical integral using Simpson's rule
	# assume a < b and n is an even positive integer
	if (a == -Inf & b == Inf) {
		f <- function(t) (fun((1-t)/t) + fun((t-1)/t))/t^2
		s <- simpson_v2(f, 0, 1, n)
	} else if (a == -Inf & b != Inf) {
		f <- function(t) fun(b-(1-t)/t)/t^2
		s <- simpson_v2(f, 0, 1, n)
	} else if (a != -Inf & b == Inf) {
		f <- function(t) fun(a+(1-t)/t)/t^2
		s <- simpson_v2(f, 0, 1, n)
	} else {
		h <- (b-a)/n
		x <- seq(a, b, by=h)
		y <- fun(x)
		y[is.nan(y)]=0
		s <- y[1] + y[n+1] + 2*sum(y[seq(2,n,by=2)]) + 4 *sum(y[seq(3,n-1, by=2)])
		s <- s*h/3
	}
	return(s)
}




f <- function(x) 1/x
#integrate(f, 0.01, 1) == -log(0.01)
S.trapezoid <- function(n) trapezoid(f, 0.01, 1, n)
S.simpson <- function(n) simpson(f, 0.01, 1, n)
 
n <- seq(10, 1000, by = 10)
St <- sapply(n, S.trapezoid)
Ss <- sapply(n, S.simpson)
 
opar <- par(mfrow = c(2, 2))
plot(n,St + log(0.01), type="l", xlab="n", ylab="error", main="Trapezoidal rule")
plot(n,Ss + log(0.01), type="l", xlab="n", ylab="error",main="Simpson's rule")
plot(log(n), log(St+log(0.01)),type="l", xlab="log(n)", ylab="log(error)",main="Trapezoidal rule")
plot(log(n), log(Ss+log(0.01)),type="l", xlab="log(n)", ylab="log(error)",main="Simpson's rule")


yIntegrate <- function(fun, a, b, tol=1e-8, method= "simpson", verbose=TRUE) {
	# numerical integral of fun from a to b, assume a < b 
	# with tolerance tol
	n <- 4
	h <- (b-a)/4
	x <- seq(a, b, by=h)
	y <- fun(x)
	yIntegrate_internal <- function(y, h, n, method) {
		if (method == "simpson") {
			s <- y[1] + y[n+1] + 4*sum(y[seq(2,n,by=2)]) + 2 *sum(y[seq(3,n-1, by=2)])
			s <- s*h/3
		} else if (method == "trapezoidal") {
			s <- h * (y[1]/2 + sum(y[2:n]) + y[n+1]/2)
		} else {
		}		
		return(s)
	}
 
	s <- yIntegrate_internal(y, h, n, method)
	s.diff <- tol + 1 # ensures to loop at once.
	while (s.diff > tol ) {
		s.old <- s
		n <- 2*n
		h <- h/2
		y[seq(1, n+1, by=2)] <- y ##reuse old fun values
		y[seq(2,n, by=2)] <- sapply(seq(a+h, b-h, by=2*h), fun)
		s <- yIntegrate_internal(y, h, n, method)
		s.diff <- abs(s-s.old)
	}
	if (verbose) {
		cat("partition size", n, "\n")
	}
	return(s)
}


quadrature <- function(fun, a, b, tol=1e-8) {
	# numerical integration using adaptive quadrature
 
	quadrature_internal <- function(S.old, fun, a, m, b, tol, level) {
		level.max <- 100
		if (level > level.max) {
			cat ("recursion limit reached: singularity likely\n")
			return (NULL)
		}
		S.left <- simpson(fun, a, m, n=2) 
		S.right <- simpson(fun, m, b, n=2)
		S.new <- S.left + S.right
		if (abs(S.new-S.old) > tol) {
			S.left <- quadrature_internal(S.left, fun, a, (a+m)/2, m, tol/2, level+1)
			S.right <- quadrature_internal(S.right, fun, m, (m+b)/2, b, tol/2, level+1)
			S.new <- S.left + S.right
		}
		return(S.new)
	}
 
	level = 1
	S.old <- (b-a) * (fun(a) + fun(b))/2
	S.new <- quadrature_internal(S.old, fun, a, (a+b)/2, b, tol, level+1)
	return(S.new)
}







trapezoidal.integration = function(x, f)
{
       ### 3 checks to ensure that the arguments are numeric and of equal lengths
       # check if the variable of integration is numeric
       if (!is.numeric(x))
       {
              stop('The variable of integration "x" is not numeric.')
       }

       # check if the integrand is numeric
       if (!is.numeric(f))
       {
              stop('The integrand "f" is not numeric.')
       }

       # check if the variable of integration and the integrand have equal lengths
       if (length(x) != length(f))
       {
              stop('The lengths of the variable of integration and the integrand do not match.')
       }

       ### finish checks

       # obtain length of variable of integration and integrand
       n = length(x)

       # integrate using the trapezoidal rule
       integral = 0.5*sum((x[2:n] - x[1:(n-1)]) * (f[2:n] + f[1:(n-1)]))

       # print the definite integral
       return(integral)
}


### Define a function for implementing rectangular integration
### Input #1: x - the points along the interval of integration
### Input #2: f - the function
### Output: the integral as approximated by rectangular integration (a.k.a. midpoint rule)
rectangular.integration = function(x, f)
{
 # check if the variable of integration is numeric
 if (!is.numeric(x))
 {
 stop('The first argument is not numeric.')
 }

 # check if f is a function
 if (!is.function(f))
 {
 stop('The second argument is not a function.')
 }

 ### finish checks

 # obtain length of variable of integration and integrand
 n.points = length(x)

 # midpoints
 midpoints = 0.5*(x[2:n.points] + x[1:(n.points-1)])

 # function evaluated at midpoints
 f.midpoints = f(midpoints)

 # calculate the widths of the intervals between adjacent pairs of points along the variable of integration
 interval.widths = x[2:n.points] - x[1:(n.points-1)]

 # implement rectangular integration
 # calculate the sum of all areas of rectangles that are used to approximate the integral
 rectangular.integral = sum(interval.widths * f.midpoints)

 # print the definite integral
 return(rectangular.integral)
}


####chaos trajectory

return<-rep(0,length(PSI20))


x<-rep<-(0,n)
chaos1<-function(x0,n) {
for (i in 1:n) {
x1<-4*x0*(1-x0)
x0<-x1
x[i]<-x1
}
return(x)
}





#####gambler ruin 


gen.ruin = function(n, x.cnt, y.cnt, x.p){
x.cnt.c = x.cnt
y.cnt.c = y.cnt
x.rnd = rbinom(n, 1, p=x.p)
x.rnd[x.rnd==0] = -1
y.rnd = x.rnd*-1
x.cum.sum = cumsum(x.rnd)+x.cnt
y.cum.sum = cumsum(y.rnd)+y.cnt
 
ruin.data = cumsum(x.rnd)+x.cnt
 
if( any( which(ruin.data>=x.cnt+y.cnt) ) | any( which(ruin.data<=0) ) ){ cut.data = 1+min( which(ruin.data>=x.cnt+y.cnt), which(ruin.data<=0) )
 
ruin.data[cut.data:length(ruin.data)] = 0
 
}
 
return(ruin.data)
 
}
n.reps = 10000
ruin.sim = replicate(n.reps, gen.ruin(n=1000, x.cnt=5, y.cnt=10, x.p=.6))
ruin.sim[ruin.sim==0] = NA
hist( apply(ruin.sim==15 | is.na(ruin.sim), 2, which.max) , nclass=100, col='8', main="Distribution of Number of Turns",
xlab="Turn Number")
abline(v=mean(apply(ruin.sim==15 | is.na(ruin.sim), 2, which.max)), lwd=3, col='red')
abline(v=median(apply(ruin.sim==15 | is.na(ruin.sim), 2, which.max)), lwd=3, col='green')
x.annihilation = apply(ruin.sim==15, 2, which.max)
( prob.x.annilate = length(x.annihilation[x.annihilation!=1]) / n.reps )
state.cnt = ruin.sim
state.cnt[state.cnt!=15] = 0
state.cnt[state.cnt==15] = 1
mean.state = apply(ruin.sim, 1, mean, na.rm=T)
plot(mean.state, xlim=c(0,which.max(mean.state)), ylim=c(0,20), ylab="Points", xlab="Number of Plays", pch=16, cex=.5, col='green')
lines(mean.state, col='green')
points(15-mean.state, pch=16, cex=.5, col='blue')
lines(15-mean.state, col='blue')





#####fixedpoint

fixedpoint <- function(fun, x0, tol=1e-07, niter=50000){
	## fixed-point algorithm to find x such that fun(x) == x
	## assume that fun is a function of a single variable
	## x0 is the initial guess at the fixed point
 
	xold <- x0
	xnew <- fun(xold)
	for (i in 1:niter) {
		xold <- xnew
		xnew <- fun(xold)
		if ( abs((xnew-xold)) < tol )
			return(xnew)
		}
	stop("exceeded allowed number of iterations")
}



f <- function(x) 1/2*(x+2/x)

gfun <- function(x) x-1/2*(x+2/x)



###############newton.raphson

newton.raphson <- function(f, a, b, tol = 1e-5, n = 100000) {
  require(numDeriv) # Package for computing f'(x)
  
  x0 <- a # Set start value to supplied lower bound
  k <- n # Initialize for iteration results
  
  # Check the upper and lower bounds to see if approximations result in 0
  fa <- f(a)
  if (fa == 0.0) {
    return(a)
  }
  
  fb <- f(b)
  if (fb == 0.0) {
    return(b)
  }

  for (i in 1:n) {
    dx <- genD(func = f, x = x0)$D[1] # First-order derivative f'(x0)
    x1 <- x0 - (f(x0) / dx) # Calculate next value x1
    k[i] <- x1 # Store x1
    # Once the difference between x0 and x1 becomes sufficiently small, output the results.
    if (abs(x1 - x0) < tol) {
      root.approx <- tail(k, n=1)
      res <- list('root approximation' = root.approx, 'iterations' = k)
      return(res)
    }
    # If Newton-Raphson has not yet reached convergence set x1 as x0 and continue
    x0 <- x1
  }
  print('Too many iterations in method')
}




newton.raphson(gfun, 1, 1.5)




bisection <- function(f, a, b, n = 1000, tol = 1e-7) {
  # If the signs of the function at the evaluated points, a and b, stop the function and return message.
  if (!(f(a) < 0) && (f(b) > 0)) {
    stop('signs of f(a) and f(b) differ')
  } else if ((f(a) > 0) && (f(b) < 0)) {
    stop('signs of f(a) and f(b) differ')
  }
  
  for (i in 1:n) {
    c <- (a + b) / 2 # Calculate midpoint
    
    # If the function equals 0 at the midpoint or the midpoint is below the desired tolerance, stop the 
    # function and return the root.
    if ((f(c) == 0) || ((b - a) / 2) < tol) {
      return(c)
    }
    
    # If another iteration is required, 
    # check the signs of the function at the points c and a and reassign
    # a or b accordingly as the midpoint to be used in the next iteration.
    ifelse(sign(f(c)) == sign(f(a)), 
           a <- c,
           b <- c)
  }
  # If the max number of iterations is reached and no root has been found, 
  # return message and end function.
  print('Too many iterations')
}






##### Implementing the golden section search method
##### a modification of the bisection method with the golden ratio

golden.section.search = function(f, lower.bound, upper.bound, tolerance)
{
   golden.ratio = 2/(sqrt(5) + 1)

   ### Use the golden ratio to set the initial test points
   x1 = upper.bound - golden.ratio*(upper.bound - lower.bound)
   x2 = lower.bound + golden.ratio*(upper.bound - lower.bound)

   ### Evaluate the function at the test points
   f1 = f(x1)
   f2 = f(x2)

   iteration = 0

   while (abs(upper.bound - lower.bound) > tolerance)
   {
      iteration = iteration + 1
      cat('', '\n')
      cat('Iteration #', iteration, '\n')
      cat('f1 =', f1, '\n')
      cat('f2 =', f2, '\n')

      if (f2 > f1)
      # then the minimum is to the left of x2
      # let x2 be the new upper bound
      # let x1 be the new upper test point
      {
         cat('f2 > f1', '\n')
         ### Set the new upper bound
         upper.bound = x2
         cat('New Upper Bound =', upper.bound, '\n')
         cat('New Lower Bound =', lower.bound, '\n')
         ### Set the new upper test point
         ### Use the special result of the golden ratio
         x2 = x1
         cat('New Upper Test Point = ', x2, '\n')
         f2 = f1

         ### Set the new lower test point
         x1 = upper.bound - golden.ratio*(upper.bound - lower.bound)
         cat('New Lower Test Point = ', x1, '\n')
         f1 = f(x1)
      } 
      else 
      {
         cat('f2 < f1', '\n')
         # the minimum is to the right of x1
         # let x1 be the new lower bound
         # let x2 be the new lower test point

         ### Set the new lower bound
         lower.bound = x1
         cat('New Upper Bound =', upper.bound, '\n')
         cat('New Lower Bound =', lower.bound, '\n')

         ### Set the new lower test point
         x1 = x2
         cat('New Lower Test Point = ', x1, '\n')

         f1 = f2

         ### Set the new upper test point
         x2 = lower.bound + golden.ratio*(upper.bound - lower.bound)
         cat('New Upper Test Point = ', x2, '\n')
         f2 = f(x2)
      }
   }

   ### Use the mid-point of the final interval as the estimate of the optimzer
   cat('', '\n')
   cat('Final Lower Bound =', lower.bound, '\n')
   cat('Final Upper Bound =', upper.bound, '\n')
   estimated.minimizer = (lower.bound + upper.bound)/2
   cat('Estimated Minimizer =', estimated.minimizer, '\n')
}



#####Here is the script that ran everything; I called it “minimization.R”.

##### Finding the minimizers of functions using the bisection method with the golden ratio


# Calling the user-defined functions in the working directory
source('golden.section.search.R')
source('f.R')

# printing the PNG images into the working directory
# png('INSERT YOUR DIRECTORY PATH HERE/cusped function.png')
# plotting the curve of my user-defined function
curve(f, from = 1, to = 3, main = expression(paste('f(x) = |x - 2| + (x - 1)'^'2')))
dev.off()

# finding the minimizer of my user-defined function using my golden bisection method
golden.section.search(f, 1, 3, 1e-5)




#########Extended Kalman filter example in R


# Logistic growth function
logistG <- function(r, p, k, t){
  k * p * exp(r*t) / (k + p * (exp(r*t) - 1))
}

k <- 100
p0 <- 0.1*k
r <- 0.2
deltaT <- 0.1

# Let's create some sample data:
set.seed(12345)

obsVariance <- 25
nObs = 250
nu <- rnorm(nObs, mean=0, sd=sqrt(obsVariance)) 
pop <- c(p0, logistG(r, p0, k, (1:(nObs-1))*deltaT)) + nu

Estimate <- data.frame(Rate=rep(NA, nObs),
                       Population=rep(NA,nObs))

library(numDeriv)
a <- function(x, k, deltaT){
  c(r=x[1],
    logistG(r=x[1], p=x[2], k, deltaT))
}
G <- t(c(0, 1))

# Evolution error
Q <- diag(c(0, 0))
# Observation error
R <-  obsVariance
# Prior
x <- c(r, p0)
Sigma <-  diag(c(144, 25))

for(i in 1:nObs){
  # Observation
  xobs <- c(0, pop[i])
  y <- G %*% xobs
  # Filter  
  SigTermInv <- solve(G %*% Sigma %*% t(G) + R)
  xf <- x + Sigma %*% t(G) %*%  SigTermInv %*% (y - G %*% x)
  Sigma <- Sigma - Sigma %*% t(G) %*% SigTermInv %*% G %*% Sigma 
  
  A <- jacobian(a, x=x, k=k, deltaT=deltaT)   
  K <- A %*% Sigma %*% t(G) %*% solve(G %*% Sigma %*% t(G) + R)
  Estimate[i,] <- x
  
  # Predict
  x <- a(x=xf, k=k, deltaT=deltaT) + K %*% (y - G %*% xf)
  Sigma <- A %*% Sigma %*% t(A) - K %*% G %*% Sigma %*% t(A) + Q
}

# Plot output
op <- par(mfrow=c(2,1))
time <- c(1:nObs)*deltaT
plot(y=pop, x=time, t='l', main="Population growth", 
     xlab="Time", ylab="Population")
curve(logistG(r, p0, k, x),  from=0, to=max(time), col=2, add=TRUE, lwd=1)
lines(y=Estimate$Population, x=time, col="orange", lwd=2)
legend("bottomright", 
       legend=c("Data","Actual", "Estimate"), 
       bty="n",
       col=c("black", "red", "orange"),
       lty=1, lwd=2)
plot(y=Estimate$Rate, x=time, t='l', main="Estimated growth rate", 
     xlab="Time", ylab="Rate", col="orange", lwd=2)
abline(h=r, col=adjustcolor("red", alpha=0.5), lwd=2)
legend("topright", 
       legend=c("Actual", "Estimate"), 
       bty="n",
       col=c("red", "orange"),
       lty=1, lwd=2)
par(op)









 gaussian.kernel.copula.surface <- function (u,v,n) {
   s=seq(1/(n+1), length=n, by=1/(n+1))
   mat=matrix(NA,nrow = n, ncol = n)
 sur=kde2d(qnorm(u),qnorm(v),n=1000,
 lims = c(-4, 4, -4, 4))
 su<-sur$z
 for (i in 1:n) {
     for (j in 1:n) {
 	Xi<-round((qnorm(s[i])+4)*1000/8)+1;
 	Yj<-round((qnorm(s[j])+4)*1000/8)+1
 	mat[i,j]<-su[Xi,Yj]/(dnorm(qnorm(s[i]))*
 	dnorm(qnorm(s[j])))
     }
 }
 return(list(x=s,y=s,z=data.matrix(mat)))
 }



student.kernel.copula.surface =
  function (u,v,n,d=4) {
  s <- seq(1/(n+1), length=n, by=1/(n+1))
  mat <- matrix(NA,nrow = n, ncol = n)
 sur<-kde2d(qt(u,df=d),qt(v,df=d),n=5000,
 lims = c(-8, 8, -8, 8))
 su<-sur$z
 for (i in 1:n) {
     for (j in 1:n) {
 	Xi<-round((qt(s[i],df=d)+8)*5000/16)+1;
 	Yj<-round((qt(s[j],df=d)+8)*5000/16)+1
 	mat[i,j]<-su[Xi,Yj]/(dt(qt(s[i],df=d),df=d)*
 	dt(qt(s[j],df=d),df=d))
     }
 }
 return(list(x=s,y=s,z=data.matrix(mat)))
 }


beta.kernel.copula.surface=
  function (u,v,bx=.025,by=.025,n) {
  s <- seq(1/(n+1), length=n, by=1/(n+1))
  mat <- matrix(0,nrow = n, ncol = n)
 for (i in 1:n) {
     a <- s[i]
     for (j in 1:n) {
     b <- s[j]
 	mat[i,j] <- sum(dbeta(a,u/bx,(1-u)/bx) *
     dbeta(b,v/by,(1-v)/by)) / length(u)
     }
}
 return(list(x=s,y=s,z=data.matrix(mat)))
 }




